{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import re\n",
    "import nltk\n",
    "import chart_studio\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "from bs4 import BeautifulSoup\n",
    "import plotly.graph_objects as go\n",
    "import chart_studio.plotly as py\n",
    "import cufflinks\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import plotly.figure_factory as ff\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "from chart_studio.plotly import iplot\n",
    "cufflinks.go_offline()\n",
    "cufflinks.set_config_file(world_readable=True, theme='pearl')\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    tool to mount ndfs on linux tool to mount ndfs...\n",
      "1    make Configuration an interface The Configurat...\n",
      "2    DF enhancement: performance and win XP support...\n",
      "3    Adding some uniformity/convenience to environm...\n",
      "4    bufferSize argument is ignored in FileSystem.c...\n",
      "Name: text, dtype: object\n",
      "fs                        900\n",
      "build                     784\n",
      "security                  631\n",
      "test                      485\n",
      "documentation             477\n",
      "ipc                       375\n",
      "io                        355\n",
      "conf                      308\n",
      "scripts                   266\n",
      "util                      265\n",
      "fs/s3                     232\n",
      "metrics                   170\n",
      "native                    136\n",
      "contrib/hod               114\n",
      "yetus                      77\n",
      "tools                      71\n",
      "ha                         68\n",
      "kms                        48\n",
      "net                        43\n",
      "record                     43\n",
      "bin                        33\n",
      "contrib/cloud              32\n",
      "tools/distcp               28\n",
      "nfs                        26\n",
      "viewfs                     24\n",
      "fs/swift                   24\n",
      "auto-failover              23\n",
      "benchmarks                 21\n",
      "performance                17\n",
      "azure                      15\n",
      "contrib/eclipse-plugin     13\n",
      "filecache                  11\n",
      "site                       11\n",
      "tracing                    10\n",
      "fs/azure                    8\n",
      "trash                       6\n",
      "contrib/serialization       2\n",
      "Name: component, dtype: int64\n",
      "Found 23333 unique tokens.\n",
      "Shape of data tensor: (6152, 250)\n",
      "(4614, 250) (4614, 37)\n",
      "(1538, 250) (1538, 37)\n"
     ]
    }
   ],
   "source": [
    "data_location_ori = 'data/hadoop/HADOOP.csv'\n",
    "\n",
    "df = pd.read_csv(data_location_ori) # 원본 데이터\n",
    "\n",
    "for x in range(len(df.component)):\n",
    "    df.component[x] = df.component[x].split(',')[0]\n",
    "\n",
    "df['text'] = list(df.title + \" \" + df.description)\n",
    "\n",
    "print(df.text.head())\n",
    "\n",
    "Y = pd.get_dummies(df[set(df.component)])\n",
    "print(df.component.value_counts())\n",
    "\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.astype(str)\n",
    "\n",
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 50000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(df['text'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "X = tokenizer.texts_to_sequences(df['text'].values)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X.shape)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.25, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 250, 100)          5000000   \n",
      "                                                                 \n",
      " spatial_dropout1d (SpatialD  (None, 250, 100)         0         \n",
      " ropout1D)                                                       \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               80400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 37)                3737      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,084,137\n",
      "Trainable params: 5,084,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(37, activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.Recall(top_k = 5)])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/65 [===>..........................] - ETA: 1:46 - loss: 3.2014 - recall: 0.5194"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-c7f9d75a08a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Users\\PiusHwang\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\PiusHwang\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3131\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3133\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1960\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 603\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    604\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 59\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(topK):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "    \n",
    "    model.add(SpatialDropout1D(0.2))\n",
    "    model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "    #model.add(LSTM(100, return_sequences=True))\n",
    "    model.add(Dense(37, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.Recall(top_k = topK)])\n",
    "    print(model.summary())\n",
    "\n",
    "    epochs = 20\n",
    "    batch_size = 100\n",
    "\n",
    "    history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
    "    df_history.append(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 250, 100)          5000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_8 (Spatial (None, 250, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 37)                3737      \n",
      "=================================================================\n",
      "Total params: 5,084,137\n",
      "Trainable params: 5,084,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 37s 742ms/step - loss: 3.4361 - recall_6: 0.5006 - val_loss: 3.2254 - val_recall_6: 0.5244\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 36s 717ms/step - loss: 3.1524 - recall_6: 0.5325 - val_loss: 3.2162 - val_recall_6: 0.5244\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 37s 735ms/step - loss: 3.1463 - recall_6: 0.5319 - val_loss: 3.1929 - val_recall_6: 0.5244\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 37s 731ms/step - loss: 3.1412 - recall_6: 0.5325 - val_loss: 3.2025 - val_recall_6: 0.5244\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 37s 735ms/step - loss: 3.1277 - recall_6: 0.5325 - val_loss: 3.1966 - val_recall_6: 0.5244\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 35s 705ms/step - loss: 3.1004 - recall_6: 0.5389 - val_loss: 3.1977 - val_recall_6: 0.5357\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 250, 100)          5000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_9 (Spatial (None, 250, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 37)                3737      \n",
      "=================================================================\n",
      "Total params: 5,084,137\n",
      "Trainable params: 5,084,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 36s 713ms/step - loss: 3.4440 - recall_7: 0.7224 - val_loss: 3.2256 - val_recall_7: 0.8003\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 37s 734ms/step - loss: 3.1578 - recall_7: 0.7814 - val_loss: 3.2065 - val_recall_7: 0.8003\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 36s 715ms/step - loss: 3.1462 - recall_7: 0.7777 - val_loss: 3.2012 - val_recall_7: 0.8003\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 36s 713ms/step - loss: 3.1383 - recall_7: 0.7833 - val_loss: 3.1991 - val_recall_7: 0.8003\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 35s 708ms/step - loss: 3.1259 - recall_7: 0.7902 - val_loss: 3.1926 - val_recall_7: 0.8003\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 38s 754ms/step - loss: 3.0912 - recall_7: 0.8015 - val_loss: 3.1721 - val_recall_7: 0.8068\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 36s 729ms/step - loss: 3.0001 - recall_7: 0.8337 - val_loss: 3.1555 - val_recall_7: 0.7857\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 38s 765ms/step - loss: 2.8350 - recall_7: 0.8629 - val_loss: 3.0894 - val_recall_7: 0.8084\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 40s 800ms/step - loss: 2.6339 - recall_7: 0.8979 - val_loss: 3.0262 - val_recall_7: 0.8133\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 40s 809ms/step - loss: 2.3758 - recall_7: 0.9174 - val_loss: 2.9832 - val_recall_7: 0.8182\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 40s 794ms/step - loss: 2.1348 - recall_7: 0.9275 - val_loss: 2.9705 - val_recall_7: 0.8084\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 39s 777ms/step - loss: 1.9100 - recall_7: 0.9380 - val_loss: 2.9152 - val_recall_7: 0.8133\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 39s 785ms/step - loss: 1.6965 - recall_7: 0.9474 - val_loss: 2.9359 - val_recall_7: 0.8052\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 39s 784ms/step - loss: 1.5360 - recall_7: 0.9551 - val_loss: 2.9621 - val_recall_7: 0.8019\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 39s 787ms/step - loss: 1.4139 - recall_7: 0.9612 - val_loss: 2.9712 - val_recall_7: 0.8117\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 250, 100)          5000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_10 (Spatia (None, 250, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 37)                3737      \n",
      "=================================================================\n",
      "Total params: 5,084,137\n",
      "Trainable params: 5,084,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 42s 839ms/step - loss: 3.4777 - recall_8: 0.8532 - val_loss: 3.2212 - val_recall_8: 0.9091\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 40s 795ms/step - loss: 3.1570 - recall_8: 0.9019 - val_loss: 3.2175 - val_recall_8: 0.8912\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 40s 807ms/step - loss: 3.1475 - recall_8: 0.9019 - val_loss: 3.2008 - val_recall_8: 0.9026\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 40s 796ms/step - loss: 3.1403 - recall_8: 0.9025 - val_loss: 3.1950 - val_recall_8: 0.9010\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 40s 794ms/step - loss: 3.1253 - recall_8: 0.9052 - val_loss: 3.1916 - val_recall_8: 0.9010\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 41s 821ms/step - loss: 3.0874 - recall_8: 0.9097 - val_loss: 3.1779 - val_recall_8: 0.9026\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 39s 789ms/step - loss: 2.9681 - recall_8: 0.9242 - val_loss: 3.1265 - val_recall_8: 0.9058\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 39s 783ms/step - loss: 2.7704 - recall_8: 0.9347 - val_loss: 3.0973 - val_recall_8: 0.9156\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 38s 769ms/step - loss: 2.5044 - recall_8: 0.9544 - val_loss: 2.9775 - val_recall_8: 0.9107\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 39s 777ms/step - loss: 2.1865 - recall_8: 0.9652 - val_loss: 2.8981 - val_recall_8: 0.8896\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 40s 794ms/step - loss: 1.8593 - recall_8: 0.9741 - val_loss: 2.8390 - val_recall_8: 0.8896\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 39s 782ms/step - loss: 1.6230 - recall_8: 0.9792 - val_loss: 2.8133 - val_recall_8: 0.8896\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 39s 783ms/step - loss: 1.4272 - recall_8: 0.9807 - val_loss: 2.7970 - val_recall_8: 0.8961\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 41s 825ms/step - loss: 1.2660 - recall_8: 0.9831 - val_loss: 2.8330 - val_recall_8: 0.8864\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 45s 906ms/step - loss: 1.1297 - recall_8: 0.9871 - val_loss: 2.8222 - val_recall_8: 0.8718\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 40s 809ms/step - loss: 1.0242 - recall_8: 0.9897 - val_loss: 2.8193 - val_recall_8: 0.8766\n"
     ]
    }
   ],
   "source": [
    "df_history = []\n",
    "for x in range(5, 16, 5):\n",
    "    run_model(x)\n",
    "    df_history.append(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [3.3167531490325928,\n",
       "  3.166748523712158,\n",
       "  3.1394078731536865,\n",
       "  3.059082508087158,\n",
       "  2.839726448059082,\n",
       "  2.5945162773132324,\n",
       "  2.3461005687713623,\n",
       "  2.126883029937744,\n",
       "  1.9392240047454834,\n",
       "  1.765804409980774],\n",
       " 'recall': [0.5076357126235962,\n",
       "  0.5295308232307434,\n",
       "  0.529714822769165,\n",
       "  0.5459061861038208,\n",
       "  0.6318307518959045,\n",
       "  0.7000920176506042,\n",
       "  0.7538178563117981,\n",
       "  0.7858325839042664,\n",
       "  0.8154553771018982,\n",
       "  0.841766357421875],\n",
       " 'val_loss': [3.2292885780334473,\n",
       "  3.209724187850952,\n",
       "  3.1954212188720703,\n",
       "  3.1329751014709473,\n",
       "  3.1253695487976074,\n",
       "  2.9463164806365967,\n",
       "  2.9692487716674805,\n",
       "  2.895751714706421,\n",
       "  2.859379768371582,\n",
       "  2.9884543418884277],\n",
       " 'val_recall': [0.5340909361839294,\n",
       "  0.524350643157959,\n",
       "  0.5211039185523987,\n",
       "  0.5324675440788269,\n",
       "  0.5389610528945923,\n",
       "  0.6071428656578064,\n",
       "  0.5827922224998474,\n",
       "  0.625,\n",
       "  0.6396104097366333,\n",
       "  0.6412337422370911]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_history[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 36ms/step - loss: 2.9402 - recall: 0.6652\n",
      "Test set\n",
      "  Loss: 2.940\n",
      "  recall: 0.665\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  recall: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(topK):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "    model.add(SpatialDropout1D(0.2))\n",
    "    model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(37, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.Recall(top_k = topK)])\n",
    "    print(model.summary())\n",
    "\n",
    "    epochs = 20\n",
    "    batch_size = 64\n",
    "\n",
    "    history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
    "    df_history.append(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 250, 20)           1000000   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 250, 20)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 248, 300)          18300     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 37)                11137     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 37)                0         \n",
      "=================================================================\n",
      "Total params: 1,029,437\n",
      "Trainable params: 1,029,437\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "78/78 [==============================] - 5s 66ms/step - loss: 0.3201 - recall_12: 0.2648 - val_loss: 0.1164 - val_recall_12: 0.5244\n",
      "Epoch 2/10\n",
      "78/78 [==============================] - 5s 60ms/step - loss: 0.1120 - recall_12: 0.5293 - val_loss: 0.1129 - val_recall_12: 0.5244\n",
      "Epoch 3/10\n",
      "78/78 [==============================] - 5s 58ms/step - loss: 0.1104 - recall_12: 0.5378 - val_loss: 0.1121 - val_recall_12: 0.5763\n",
      "Epoch 4/10\n",
      "78/78 [==============================] - 5s 58ms/step - loss: 0.1083 - recall_12: 0.5612 - val_loss: 0.1081 - val_recall_12: 0.5649\n",
      "Epoch 5/10\n",
      "78/78 [==============================] - 5s 61ms/step - loss: 0.1023 - recall_12: 0.6138 - val_loss: 0.1012 - val_recall_12: 0.6429\n",
      "Epoch 6/10\n",
      "78/78 [==============================] - 5s 64ms/step - loss: 0.0935 - recall_12: 0.6868 - val_loss: 0.0932 - val_recall_12: 0.7192\n",
      "Epoch 7/10\n",
      "78/78 [==============================] - 5s 61ms/step - loss: 0.0860 - recall_12: 0.7409 - val_loss: 0.0879 - val_recall_12: 0.7354\n",
      "Epoch 8/10\n",
      "78/78 [==============================] - 5s 62ms/step - loss: 0.0789 - recall_12: 0.7952 - val_loss: 0.0822 - val_recall_12: 0.7614\n",
      "Epoch 9/10\n",
      "78/78 [==============================] - 5s 63ms/step - loss: 0.0710 - recall_12: 0.8269 - val_loss: 0.0769 - val_recall_12: 0.7955\n",
      "Epoch 10/10\n",
      "78/78 [==============================] - 5s 62ms/step - loss: 0.0641 - recall_12: 0.8603 - val_loss: 0.0730 - val_recall_12: 0.8133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1df9fce8d48>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 6ms/step - loss: 0.0744 - recall_12: 0.7857\n",
      "Test set\n",
      "  Loss: 0.074\n",
      "  recall: 0.786\n"
     ]
    }
   ],
   "source": [
    "filter_length = 300\n",
    "num_classes = 37\n",
    "\n",
    "modelCNN = tf.keras.Sequential()\n",
    "modelCNN.add(Embedding(MAX_NB_WORDS, 20, input_length= MAX_SEQUENCE_LENGTH))\n",
    "modelCNN.add(Dropout(0.1))\n",
    "modelCNN.add(tf.keras.layers.Conv1D(filter_length, 3, padding = 'valid', activation = 'relu', strides = 1))\n",
    "modelCNN.add(tf.keras.layers.GlobalMaxPool1D())\n",
    "modelCNN.add(Dense(num_classes))\n",
    "modelCNN.add(tf.keras.layers.Activation('sigmoid'))\n",
    "\n",
    "modelCNN.compile(optimizer = 'adam', loss  = 'binary_crossentropy', metrics = [tf.keras.metrics.Recall(top_k = 5)])\n",
    "\n",
    "modelCNN.summary()\n",
    "modelCNN.fit(X_train, Y_train, epochs=10, batch_size = 64, validation_split=0.1)\n",
    "\n",
    "accr = modelCNN.evaluate(X_test, Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  recall: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2cafbbdf5f0c485b1a1935b2358d1e2de8ca6414272176d54707d0003e55811a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
