{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import re\n",
    "import nltk\n",
    "import chart_studio\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "from bs4 import BeautifulSoup\n",
    "import plotly.graph_objects as go\n",
    "import chart_studio.plotly as py\n",
    "import cufflinks\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import plotly.figure_factory as ff\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "from chart_studio.plotly import iplot\n",
    "cufflinks.go_offline()\n",
    "cufflinks.set_config_file(world_readable=True, theme='pearl')\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\PIUSHW~1\\AppData\\Local\\Temp/ipykernel_3280/699186390.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdata_location_ori\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'data/hadoop/HADOOP.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_location_ori\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 원본 데이터\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "data_location_ori = 'data/hadoop/HADOOP.csv'\n",
    "\n",
    "df = pd.read_csv(data_location_ori) # 원본 데이터\n",
    "\n",
    "for x in range(len(df.component)):\n",
    "    df.component[x] = df.component[x].split(',')[0]\n",
    "\n",
    "df['text'] = list(df.title + \" \" + df.description)\n",
    "\n",
    "print(df.text.head())\n",
    "\n",
    "Y = pd.get_dummies(df[set(df.component)])\n",
    "print(df.component.value_counts())\n",
    "\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.astype(str)\n",
    "\n",
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 50000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(df['text'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "X = tokenizer.texts_to_sequences(df['text'].values)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X.shape)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.25, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 250, 100)          5000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 250, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 37)                3737      \n",
      "=================================================================\n",
      "Total params: 5,084,137\n",
      "Trainable params: 5,084,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(37, activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.Recall(top_k = 5)])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "78/78 [==============================] - 38s 489ms/step - loss: 3.3168 - recall: 0.5076 - val_loss: 3.2293 - val_recall: 0.5341\n",
      "Epoch 2/10\n",
      "78/78 [==============================] - 38s 481ms/step - loss: 3.1667 - recall: 0.5295 - val_loss: 3.2097 - val_recall: 0.5244\n",
      "Epoch 3/10\n",
      "78/78 [==============================] - 38s 486ms/step - loss: 3.1394 - recall: 0.5297 - val_loss: 3.1954 - val_recall: 0.5211\n",
      "Epoch 4/10\n",
      "78/78 [==============================] - 37s 480ms/step - loss: 3.0591 - recall: 0.5459 - val_loss: 3.1330 - val_recall: 0.5325\n",
      "Epoch 5/10\n",
      "78/78 [==============================] - 38s 491ms/step - loss: 2.8397 - recall: 0.6318 - val_loss: 3.1254 - val_recall: 0.5390\n",
      "Epoch 6/10\n",
      "78/78 [==============================] - 37s 471ms/step - loss: 2.5945 - recall: 0.7001 - val_loss: 2.9463 - val_recall: 0.6071\n",
      "Epoch 7/10\n",
      "78/78 [==============================] - 42s 534ms/step - loss: 2.3461 - recall: 0.7538 - val_loss: 2.9692 - val_recall: 0.5828\n",
      "Epoch 8/10\n",
      "78/78 [==============================] - 39s 499ms/step - loss: 2.1269 - recall: 0.7858 - val_loss: 2.8958 - val_recall: 0.6250\n",
      "Epoch 9/10\n",
      "78/78 [==============================] - 40s 508ms/step - loss: 1.9392 - recall: 0.8155 - val_loss: 2.8594 - val_recall: 0.6396\n",
      "Epoch 10/10\n",
      "78/78 [==============================] - 40s 513ms/step - loss: 1.7658 - recall: 0.8418 - val_loss: 2.9885 - val_recall: 0.6412\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(topK):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "    \n",
    "    model.add(SpatialDropout1D(0.2))\n",
    "    model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "    #model.add(LSTM(100, return_sequences=True))\n",
    "    model.add(Dense(37, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.Recall(top_k = topK)])\n",
    "    print(model.summary())\n",
    "\n",
    "    epochs = 20\n",
    "    batch_size = 100\n",
    "\n",
    "    history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
    "    df_history.append(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 250, 100)          5000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_8 (Spatial (None, 250, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 37)                3737      \n",
      "=================================================================\n",
      "Total params: 5,084,137\n",
      "Trainable params: 5,084,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 37s 742ms/step - loss: 3.4361 - recall_6: 0.5006 - val_loss: 3.2254 - val_recall_6: 0.5244\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 36s 717ms/step - loss: 3.1524 - recall_6: 0.5325 - val_loss: 3.2162 - val_recall_6: 0.5244\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 37s 735ms/step - loss: 3.1463 - recall_6: 0.5319 - val_loss: 3.1929 - val_recall_6: 0.5244\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 37s 731ms/step - loss: 3.1412 - recall_6: 0.5325 - val_loss: 3.2025 - val_recall_6: 0.5244\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 37s 735ms/step - loss: 3.1277 - recall_6: 0.5325 - val_loss: 3.1966 - val_recall_6: 0.5244\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 35s 705ms/step - loss: 3.1004 - recall_6: 0.5389 - val_loss: 3.1977 - val_recall_6: 0.5357\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 250, 100)          5000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_9 (Spatial (None, 250, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 37)                3737      \n",
      "=================================================================\n",
      "Total params: 5,084,137\n",
      "Trainable params: 5,084,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 36s 713ms/step - loss: 3.4440 - recall_7: 0.7224 - val_loss: 3.2256 - val_recall_7: 0.8003\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 37s 734ms/step - loss: 3.1578 - recall_7: 0.7814 - val_loss: 3.2065 - val_recall_7: 0.8003\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 36s 715ms/step - loss: 3.1462 - recall_7: 0.7777 - val_loss: 3.2012 - val_recall_7: 0.8003\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 36s 713ms/step - loss: 3.1383 - recall_7: 0.7833 - val_loss: 3.1991 - val_recall_7: 0.8003\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 35s 708ms/step - loss: 3.1259 - recall_7: 0.7902 - val_loss: 3.1926 - val_recall_7: 0.8003\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 38s 754ms/step - loss: 3.0912 - recall_7: 0.8015 - val_loss: 3.1721 - val_recall_7: 0.8068\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 36s 729ms/step - loss: 3.0001 - recall_7: 0.8337 - val_loss: 3.1555 - val_recall_7: 0.7857\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 38s 765ms/step - loss: 2.8350 - recall_7: 0.8629 - val_loss: 3.0894 - val_recall_7: 0.8084\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 40s 800ms/step - loss: 2.6339 - recall_7: 0.8979 - val_loss: 3.0262 - val_recall_7: 0.8133\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 40s 809ms/step - loss: 2.3758 - recall_7: 0.9174 - val_loss: 2.9832 - val_recall_7: 0.8182\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 40s 794ms/step - loss: 2.1348 - recall_7: 0.9275 - val_loss: 2.9705 - val_recall_7: 0.8084\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 39s 777ms/step - loss: 1.9100 - recall_7: 0.9380 - val_loss: 2.9152 - val_recall_7: 0.8133\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 39s 785ms/step - loss: 1.6965 - recall_7: 0.9474 - val_loss: 2.9359 - val_recall_7: 0.8052\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 39s 784ms/step - loss: 1.5360 - recall_7: 0.9551 - val_loss: 2.9621 - val_recall_7: 0.8019\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 39s 787ms/step - loss: 1.4139 - recall_7: 0.9612 - val_loss: 2.9712 - val_recall_7: 0.8117\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 250, 100)          5000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_10 (Spatia (None, 250, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 37)                3737      \n",
      "=================================================================\n",
      "Total params: 5,084,137\n",
      "Trainable params: 5,084,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 42s 839ms/step - loss: 3.4777 - recall_8: 0.8532 - val_loss: 3.2212 - val_recall_8: 0.9091\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 40s 795ms/step - loss: 3.1570 - recall_8: 0.9019 - val_loss: 3.2175 - val_recall_8: 0.8912\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 40s 807ms/step - loss: 3.1475 - recall_8: 0.9019 - val_loss: 3.2008 - val_recall_8: 0.9026\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 40s 796ms/step - loss: 3.1403 - recall_8: 0.9025 - val_loss: 3.1950 - val_recall_8: 0.9010\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 40s 794ms/step - loss: 3.1253 - recall_8: 0.9052 - val_loss: 3.1916 - val_recall_8: 0.9010\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 41s 821ms/step - loss: 3.0874 - recall_8: 0.9097 - val_loss: 3.1779 - val_recall_8: 0.9026\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 39s 789ms/step - loss: 2.9681 - recall_8: 0.9242 - val_loss: 3.1265 - val_recall_8: 0.9058\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 39s 783ms/step - loss: 2.7704 - recall_8: 0.9347 - val_loss: 3.0973 - val_recall_8: 0.9156\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 38s 769ms/step - loss: 2.5044 - recall_8: 0.9544 - val_loss: 2.9775 - val_recall_8: 0.9107\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 39s 777ms/step - loss: 2.1865 - recall_8: 0.9652 - val_loss: 2.8981 - val_recall_8: 0.8896\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 40s 794ms/step - loss: 1.8593 - recall_8: 0.9741 - val_loss: 2.8390 - val_recall_8: 0.8896\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 39s 782ms/step - loss: 1.6230 - recall_8: 0.9792 - val_loss: 2.8133 - val_recall_8: 0.8896\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 39s 783ms/step - loss: 1.4272 - recall_8: 0.9807 - val_loss: 2.7970 - val_recall_8: 0.8961\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 41s 825ms/step - loss: 1.2660 - recall_8: 0.9831 - val_loss: 2.8330 - val_recall_8: 0.8864\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 45s 906ms/step - loss: 1.1297 - recall_8: 0.9871 - val_loss: 2.8222 - val_recall_8: 0.8718\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 40s 809ms/step - loss: 1.0242 - recall_8: 0.9897 - val_loss: 2.8193 - val_recall_8: 0.8766\n"
     ]
    }
   ],
   "source": [
    "df_history = []\n",
    "for x in range(5, 16, 5):\n",
    "    run_model(x)\n",
    "    df_history.append(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [3.3167531490325928,\n",
       "  3.166748523712158,\n",
       "  3.1394078731536865,\n",
       "  3.059082508087158,\n",
       "  2.839726448059082,\n",
       "  2.5945162773132324,\n",
       "  2.3461005687713623,\n",
       "  2.126883029937744,\n",
       "  1.9392240047454834,\n",
       "  1.765804409980774],\n",
       " 'recall': [0.5076357126235962,\n",
       "  0.5295308232307434,\n",
       "  0.529714822769165,\n",
       "  0.5459061861038208,\n",
       "  0.6318307518959045,\n",
       "  0.7000920176506042,\n",
       "  0.7538178563117981,\n",
       "  0.7858325839042664,\n",
       "  0.8154553771018982,\n",
       "  0.841766357421875],\n",
       " 'val_loss': [3.2292885780334473,\n",
       "  3.209724187850952,\n",
       "  3.1954212188720703,\n",
       "  3.1329751014709473,\n",
       "  3.1253695487976074,\n",
       "  2.9463164806365967,\n",
       "  2.9692487716674805,\n",
       "  2.895751714706421,\n",
       "  2.859379768371582,\n",
       "  2.9884543418884277],\n",
       " 'val_recall': [0.5340909361839294,\n",
       "  0.524350643157959,\n",
       "  0.5211039185523987,\n",
       "  0.5324675440788269,\n",
       "  0.5389610528945923,\n",
       "  0.6071428656578064,\n",
       "  0.5827922224998474,\n",
       "  0.625,\n",
       "  0.6396104097366333,\n",
       "  0.6412337422370911]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_history[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 36ms/step - loss: 2.9402 - recall: 0.6652\n",
      "Test set\n",
      "  Loss: 2.940\n",
      "  recall: 0.665\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  recall: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(topK):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "    model.add(SpatialDropout1D(0.2))\n",
    "    model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(37, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.Recall(top_k = topK)])\n",
    "    print(model.summary())\n",
    "\n",
    "    epochs = 20\n",
    "    batch_size = 64\n",
    "\n",
    "    history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
    "    df_history.append(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 250, 20)           1000000   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 250, 20)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 248, 300)          18300     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 37)                11137     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 37)                0         \n",
      "=================================================================\n",
      "Total params: 1,029,437\n",
      "Trainable params: 1,029,437\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "78/78 [==============================] - 5s 66ms/step - loss: 0.3201 - recall_12: 0.2648 - val_loss: 0.1164 - val_recall_12: 0.5244\n",
      "Epoch 2/10\n",
      "78/78 [==============================] - 5s 60ms/step - loss: 0.1120 - recall_12: 0.5293 - val_loss: 0.1129 - val_recall_12: 0.5244\n",
      "Epoch 3/10\n",
      "78/78 [==============================] - 5s 58ms/step - loss: 0.1104 - recall_12: 0.5378 - val_loss: 0.1121 - val_recall_12: 0.5763\n",
      "Epoch 4/10\n",
      "78/78 [==============================] - 5s 58ms/step - loss: 0.1083 - recall_12: 0.5612 - val_loss: 0.1081 - val_recall_12: 0.5649\n",
      "Epoch 5/10\n",
      "78/78 [==============================] - 5s 61ms/step - loss: 0.1023 - recall_12: 0.6138 - val_loss: 0.1012 - val_recall_12: 0.6429\n",
      "Epoch 6/10\n",
      "78/78 [==============================] - 5s 64ms/step - loss: 0.0935 - recall_12: 0.6868 - val_loss: 0.0932 - val_recall_12: 0.7192\n",
      "Epoch 7/10\n",
      "78/78 [==============================] - 5s 61ms/step - loss: 0.0860 - recall_12: 0.7409 - val_loss: 0.0879 - val_recall_12: 0.7354\n",
      "Epoch 8/10\n",
      "78/78 [==============================] - 5s 62ms/step - loss: 0.0789 - recall_12: 0.7952 - val_loss: 0.0822 - val_recall_12: 0.7614\n",
      "Epoch 9/10\n",
      "78/78 [==============================] - 5s 63ms/step - loss: 0.0710 - recall_12: 0.8269 - val_loss: 0.0769 - val_recall_12: 0.7955\n",
      "Epoch 10/10\n",
      "78/78 [==============================] - 5s 62ms/step - loss: 0.0641 - recall_12: 0.8603 - val_loss: 0.0730 - val_recall_12: 0.8133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1df9fce8d48>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 6ms/step - loss: 0.0744 - recall_12: 0.7857\n",
      "Test set\n",
      "  Loss: 0.074\n",
      "  recall: 0.786\n"
     ]
    }
   ],
   "source": [
    "filter_length = 300\n",
    "num_classes = 37\n",
    "\n",
    "modelCNN = tf.keras.Sequential()\n",
    "modelCNN.add(Embedding(MAX_NB_WORDS, 20, input_length= MAX_SEQUENCE_LENGTH))\n",
    "modelCNN.add(Dropout(0.1))\n",
    "modelCNN.add(tf.keras.layers.Conv1D(filter_length, 3, padding = 'valid', activation = 'relu', strides = 1))\n",
    "modelCNN.add(tf.keras.layers.GlobalMaxPool1D())\n",
    "modelCNN.add(Dense(num_classes))\n",
    "modelCNN.add(tf.keras.layers.Activation('sigmoid'))\n",
    "\n",
    "modelCNN.compile(optimizer = 'adam', loss  = 'binary_crossentropy', metrics = [tf.keras.metrics.Recall(top_k = 5)])\n",
    "\n",
    "modelCNN.summary()\n",
    "modelCNN.fit(X_train, Y_train, epochs=10, batch_size = 64, validation_split=0.1)\n",
    "\n",
    "accr = modelCNN.evaluate(X_test, Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  recall: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2cafbbdf5f0c485b1a1935b2358d1e2de8ca6414272176d54707d0003e55811a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
